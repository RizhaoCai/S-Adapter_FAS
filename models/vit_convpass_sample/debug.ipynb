{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import timm\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "class Conv2d_cd(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n",
    "                 padding=1, dilation=1, groups=1, bias=False, adaptive_type='learnable', theta_init=0.5):\n",
    "\n",
    "        super(Conv2d_cd, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "        self.adaptive_type = adaptive_type\n",
    "        if self.adaptive_type == 'learnable':\n",
    "            self.theta = torch.nn.parameter.Parameter(torch.tensor(0.0,requires_grad=True))  # init: 0 - after sigmoid - 0.5\n",
    "\n",
    "        elif self.adaptive_type == 'layer_attn':\n",
    "            #self.down_scale = torch.nn.Linear(out_channels, out_channels//2)\n",
    "\n",
    "            self.channel_pooling = torch.nn.Conv2d(out_channels, 1, kernel_size=(1,1), stride=1, padding=0)\n",
    "            self.attn_layer1 = torch.nn.Linear(2, 4)\n",
    "            self.attn_layer2 = torch.nn.Linear(4, 2)\n",
    "\n",
    "        elif self.adaptive_type == 'channel_attn':\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def calculate_layer_attn_for_theta(self, conv_feat, cdc_feat):\n",
    "\n",
    "        # conv_feat (b, c_out, h, w) ->  (b, c_out)\n",
    "\n",
    "        conv_feat_d = torch.nn.functional.adaptive_avg_pool2d(conv_feat, (1,1)) # (b, 1)\n",
    "        conv_feat_d = self.channel_pooling(conv_feat_d)\n",
    "        cdc_feat_d = torch.nn.functional.adaptive_avg_pool2d(cdc_feat, (1,1)) # (b, 1)\n",
    "        cdc_feat_d = self.channel_pooling(cdc_feat_d)\n",
    "        cat_feat = torch.cat([conv_feat_d, cdc_feat_d], 1).squeeze(dim=3).squeeze(dim=2)\n",
    "        print(cat_feat.size())\n",
    "\n",
    "        atten_logit = self.attn_layer2(F.relu(self.attn_layer1(cat_feat)))\n",
    "        theta_attention = torch.softmax(atten_logit,1)[:,1].view(-1,1,1,1)\n",
    "        print(theta_attention.size())\n",
    "        return theta_attention\n",
    "\n",
    "    def calculate_channel_attn_for_theta(self, conv_feat, cdc_feat):\n",
    "\n",
    "        # conv_feat (b, c_out, h, w) ->  (b, c_out)\n",
    "\n",
    "        conv_feat_d = torch.nn.functional.adaptive_avg_pool3d(conv_feat, (1,1,1)).view(conv_feat.size(0),1) # (b, 1)\n",
    "        cdc_feat_d = torch.nn.functional.adaptive_avg_pool3d(cdc_feat, (1,1,1)).view(conv_feat.size(0),1) # (b, 1)\n",
    "\n",
    "        cat_feat = torch.cat( [conv_feat_d, cdc_feat_d], 1) # (b,2)\n",
    "\n",
    "        atten_logit = self.attn_layer(cat_feat)\n",
    "        theta_attention = torch.sigmoid(atten_logit,1)[:,1].view(-1,1,1,1)\n",
    "        print(theta_attention.size())\n",
    "        return theta_attention\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_normal = self.conv(x)\n",
    "\n",
    "        if self.adaptive_type == 'learnable':\n",
    "            # theta = (1+torch.tanh(self.theta)) # constrain to 0~1\n",
    "            theta = torch.sigmoid(self.theta)  # constrain to 0~1\n",
    "\n",
    "        if self.adaptive_type == 'layer_attn':\n",
    "            theta = 0.5\n",
    "\n",
    "        if math.fabs(theta - 0.0) < 1e-8:\n",
    "            return out_normal\n",
    "        else:\n",
    "            [C_out,C_in, kernel_size,kernel_size] = self.conv.weight.shape\n",
    "            kernel_diff = self.conv.weight.sum(2).sum(2)\n",
    "            kernel_diff = kernel_diff[:, :, None, None]\n",
    "            out_diff = F.conv2d(input=x, weight=kernel_diff, bias=self.conv.bias, stride=self.conv.stride, padding=0, groups=self.conv.groups)\n",
    "\n",
    "\n",
    "\n",
    "            if self.adaptive_type == 'layer_attn':\n",
    "                layer_attn_theta = self.calculate_layer_attn_for_theta(out_normal, out_diff)\n",
    "                print(layer_attn_theta.size())\n",
    "                print(out_diff.size())\n",
    "                return out_normal - layer_attn_theta * out_diff\n",
    "\n",
    "            if self.adaptive_type == 'channel_attn':\n",
    "                layer_attn_theta = self.calculate_layer_attn_for_theta(out_normal, out_diff)\n",
    "                return out_normal - layer_attn_theta * out_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2, 1, 1, 1])\n",
      "torch.Size([2, 1, 1, 1])\n",
      "torch.Size([2, 8, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[-4.6084e-02, -2.2194e-01,  1.6116e-01,  ..., -1.0496e-01,\n           -1.4926e-02,  4.3239e-02],\n          [ 1.7068e-02,  5.5577e-02, -1.5669e-01,  ..., -2.8768e-01,\n            1.1116e-01, -3.6284e-03],\n          [-1.5329e-01,  1.6896e-01, -2.8063e-01,  ...,  2.0391e-02,\n            2.8652e-02, -1.5282e-01],\n          ...,\n          [-2.1883e-01,  1.7996e-01, -1.6431e-01,  ...,  1.7076e-01,\n            9.3656e-02,  1.8757e-01],\n          [-2.0693e-02,  3.1210e-02,  1.5915e-01,  ...,  1.8637e-01,\n           -4.5829e-01,  3.8566e-03],\n          [ 1.6681e-01, -1.6647e-01,  4.8291e-01,  ...,  6.9550e-02,\n            2.1436e-01,  1.9593e-02]],\n\n         [[-1.1945e-01,  5.6504e-01, -6.8770e-02,  ..., -2.3456e-01,\n            2.2841e-01, -1.6089e-02],\n          [ 6.9756e-02,  5.1129e-01,  6.5183e-02,  ...,  3.0130e-01,\n            2.6899e-01,  4.4122e-01],\n          [ 1.8591e-01,  2.7597e-01, -1.2126e-01,  ...,  4.6521e-01,\n            2.1639e-01, -1.1583e-01],\n          ...,\n          [ 1.7970e-01,  2.8706e-01,  1.9528e-01,  ...,  3.2885e-01,\n            3.4698e-01,  3.8150e-01],\n          [ 9.1957e-02,  1.0891e-01,  2.6876e-01,  ...,  2.6434e-01,\n            2.1005e-01,  2.2744e-01],\n          [-4.4511e-02,  4.8629e-02,  2.9523e-02,  ..., -7.1187e-02,\n           -2.2735e-02, -2.5450e-01]],\n\n         [[ 1.1988e-01,  3.9016e-01,  4.4359e-01,  ...,  1.9788e-01,\n            2.9207e-01,  1.0595e-01],\n          [-7.8265e-02,  4.3578e-01,  8.4590e-02,  ...,  3.7984e-01,\n            3.4756e-01,  1.5036e-01],\n          [ 2.2205e-01,  2.4623e-01,  1.7057e-01,  ...,  3.9526e-01,\n            4.4016e-01, -1.4405e-01],\n          ...,\n          [ 2.5221e-01,  5.0547e-01,  6.7621e-01,  ...,  1.4271e-01,\n            1.8709e-01,  4.7680e-02],\n          [ 1.1972e-01, -1.0967e-01,  6.1418e-01,  ...,  3.5840e-01,\n            4.3941e-01, -1.8436e-01],\n          [ 5.0200e-03, -1.1613e-01,  1.4983e-01,  ..., -8.3540e-02,\n            1.9840e-01, -4.9278e-01]],\n\n         ...,\n\n         [[-3.5660e-03,  3.9778e-01, -4.7191e-02,  ...,  4.8770e-02,\n            1.5018e-01,  2.5586e-01],\n          [ 1.4274e-02,  1.5178e-01,  8.1805e-02,  ...,  2.5078e-01,\n            1.3490e-02, -4.2437e-03],\n          [-7.2991e-02,  3.3343e-01, -1.2445e-01,  ...,  4.3048e-01,\n           -1.0423e-01,  1.0936e-01],\n          ...,\n          [ 1.8540e-01,  1.7091e-02,  1.4609e-01,  ...,  2.2600e-01,\n           -2.6902e-02, -5.5886e-02],\n          [ 3.2314e-01, -4.0680e-02,  1.6683e-01,  ...,  1.7612e-01,\n           -1.8625e-01,  8.0095e-02],\n          [ 1.6386e-01, -2.2773e-01, -5.3820e-02,  ..., -1.2815e-01,\n            3.7786e-02, -4.5310e-02]],\n\n         [[-5.8341e-02,  8.6336e-04,  5.7345e-02,  ...,  8.2117e-02,\n           -1.1319e-01, -1.6065e-01],\n          [ 3.9062e-01, -8.0307e-02,  5.5194e-01,  ...,  1.5718e-01,\n           -5.2609e-02,  1.7249e-01],\n          [ 1.5634e-01,  5.7529e-02,  3.1950e-01,  ...,  1.3617e-02,\n            2.4666e-01, -1.8786e-01],\n          ...,\n          [-2.9517e-03, -1.9738e-04, -1.6077e-02,  ...,  1.4633e-01,\n            3.1305e-01,  1.8475e-01],\n          [ 1.4425e-01,  1.4440e-01,  1.3410e-01,  ...,  2.7995e-01,\n            2.2718e-01, -2.9482e-02],\n          [ 7.7918e-02,  4.4323e-02,  8.1955e-02,  ...,  2.7823e-02,\n            4.6734e-02,  2.5244e-02]],\n\n         [[ 5.1981e-02,  9.6355e-02, -4.7377e-02,  ...,  2.7636e-01,\n           -5.3660e-02,  4.4399e-02],\n          [ 2.4474e-01, -2.8467e-01,  8.7500e-02,  ...,  4.5559e-02,\n            3.1130e-01,  9.0989e-03],\n          [-1.5668e-01,  3.2666e-01,  1.8691e-01,  ..., -1.4386e-01,\n           -2.9415e-03,  2.9163e-01],\n          ...,\n          [-7.3464e-02, -8.9263e-02,  4.4296e-01,  ...,  2.7259e-01,\n            2.1850e-01,  1.5318e-01],\n          [-2.0734e-01,  2.4671e-01,  2.4395e-01,  ...,  2.7134e-01,\n            3.2682e-01, -4.4404e-02],\n          [ 9.0612e-02, -1.8666e-01,  3.5978e-01,  ..., -1.1301e-01,\n            3.2265e-01, -3.4845e-02]]],\n\n\n        [[[ 8.9659e-02, -3.8082e-01, -1.6003e-01,  ..., -8.2458e-02,\n           -4.0089e-01,  9.4232e-02],\n          [-1.7477e-01,  1.4655e-02,  3.6387e-01,  ..., -3.0785e-01,\n           -1.8233e-01,  1.2679e-01],\n          [ 6.1358e-03,  2.4206e-01, -3.4442e-01,  ...,  1.4274e-01,\n            1.2205e-01,  1.8670e-01],\n          ...,\n          [-3.5753e-01, -9.0247e-02, -1.9615e-01,  ..., -2.6732e-01,\n           -1.7168e-01,  4.3470e-02],\n          [ 2.1236e-01,  1.8291e-02, -7.4517e-02,  ..., -3.3582e-01,\n            4.3446e-02, -7.6275e-02],\n          [ 3.6723e-01, -9.0302e-02,  4.7913e-01,  ...,  2.7884e-01,\n            2.0149e-01,  1.0505e-01]],\n\n         [[ 1.4638e-01,  1.1000e-01,  1.1219e-01,  ...,  3.3081e-01,\n            2.2798e-01,  4.0293e-02],\n          [-1.6009e-01,  6.0722e-01,  1.2115e-01,  ...,  3.3333e-01,\n            4.7400e-01, -1.4567e-01],\n          [-1.2935e-01,  2.7039e-01,  1.7903e-01,  ...,  3.8431e-01,\n            2.0576e-01,  9.1816e-02],\n          ...,\n          [ 1.3920e-02,  5.3099e-02,  5.1811e-01,  ...,  3.0649e-01,\n            5.4155e-01, -1.8729e-01],\n          [ 4.0214e-01,  1.3329e-01,  4.5389e-01,  ...,  2.0948e-01,\n            3.1189e-01,  1.4734e-01],\n          [ 2.6624e-01, -4.0182e-01,  2.1493e-01,  ...,  1.4562e-01,\n           -1.8463e-01, -3.5429e-02]],\n\n         [[ 3.0477e-01,  3.5338e-01,  5.9036e-01,  ...,  1.6561e-01,\n            2.2500e-01,  2.8487e-01],\n          [ 2.3370e-01,  1.3873e-01,  1.4606e-01,  ...,  4.5204e-01,\n            4.2342e-01, -1.2857e-01],\n          [ 9.0577e-02,  1.6959e-01,  3.9685e-01,  ...,  3.7554e-01,\n            1.6551e-01,  1.3855e-01],\n          ...,\n          [ 3.0305e-01,  2.8220e-01,  3.5550e-01,  ...,  7.6548e-02,\n            4.2594e-01,  9.6437e-02],\n          [ 2.0650e-01,  4.5645e-01,  4.4528e-01,  ...,  4.3215e-01,\n            3.7016e-01, -3.3650e-02],\n          [ 1.1775e-02,  1.1691e-01, -1.1834e-01,  ...,  3.3207e-02,\n           -2.1509e-01, -3.1694e-01]],\n\n         ...,\n\n         [[ 2.1895e-01,  5.6212e-02, -2.0627e-02,  ...,  1.4004e-01,\n            2.2838e-01,  1.2265e-02],\n          [-2.9608e-02,  3.7058e-01, -5.5589e-02,  ...,  8.2418e-02,\n            1.6095e-01, -1.1955e-01],\n          [ 2.9212e-01,  3.5181e-02, -1.3414e-02,  ...,  1.6126e-01,\n            3.6051e-01,  4.9815e-02],\n          ...,\n          [ 4.6626e-02,  2.1080e-01, -1.4286e-01,  ...,  1.3446e-01,\n            9.0083e-02, -2.5389e-01],\n          [ 5.2458e-01,  1.1231e-01,  1.1997e-01,  ..., -4.6556e-02,\n            1.5542e-01,  1.9724e-01],\n          [ 2.1489e-01, -1.0079e-01, -1.0158e-01,  ...,  1.4045e-01,\n            6.6904e-02, -1.5574e-01]],\n\n         [[ 1.4990e-01,  1.0133e-02, -1.0788e-02,  ...,  3.0080e-01,\n            5.4705e-02, -4.6377e-02],\n          [ 2.2634e-01,  5.1786e-02, -2.2649e-02,  ...,  1.5481e-01,\n           -8.2050e-02,  2.3142e-01],\n          [ 2.4254e-01,  7.9609e-02,  2.8752e-01,  ..., -1.1124e-01,\n            3.3220e-03,  1.6905e-01],\n          ...,\n          [ 6.2702e-02,  7.3784e-02,  2.8331e-01,  ...,  2.1956e-01,\n            2.2365e-01,  2.1433e-01],\n          [ 6.1443e-02,  2.4070e-01,  2.0324e-01,  ...,  7.6212e-02,\n           -2.2925e-01,  5.6964e-02],\n          [ 8.3957e-02, -2.8069e-02, -2.1769e-01,  ..., -8.5054e-02,\n            1.6330e-01,  2.2493e-01]],\n\n         [[-9.9183e-02,  7.9765e-02,  4.3095e-01,  ...,  2.4177e-01,\n            1.0458e-01,  2.1099e-01],\n          [-6.4123e-02,  9.5750e-02, -1.0866e-01,  ...,  6.1803e-01,\n            1.2538e-01,  7.7991e-02],\n          [-1.6496e-01,  2.5672e-01,  4.9072e-01,  ...,  2.6159e-01,\n            6.5830e-02,  5.8520e-02],\n          ...,\n          [ 1.4666e-01, -2.6176e-03,  4.2737e-01,  ...,  5.2831e-01,\n           -7.4786e-02,  2.6329e-01],\n          [-1.0671e-01, -4.2341e-02,  4.4348e-01,  ...,  4.8452e-01,\n           -1.8014e-01, -8.0896e-02],\n          [-4.2370e-01,  2.3099e-01, -2.6779e-02,  ...,  1.4305e-01,\n            1.0524e-01,  3.9901e-01]]]], grad_fn=<SubBackward0>)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Conv2d_cd(4,8, adaptive_type='layer_attn')\n",
    "x = torch.rand(2,4,16,16)\n",
    "model(x)\n",
    "\n",
    "#model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention,self).__init__()\n",
    "\n",
    "        self.conv2d = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=5, stride=1, padding=2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        avgout = torch.mean(x,dim=1, keepdim=True)\n",
    "        maxout, _ = torch.max(x, dim=1, keepdim=True)\n",
    "\n",
    "        out = torch.cat([avgout, maxout], dim=1)\n",
    "        out = self.sigmoid(self.conv2d(out))\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}